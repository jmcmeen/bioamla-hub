{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave File Dissection (Basics)\n",
    "\n",
    "A Wave file is a type of audio file that contains uncompressed, uncompressed digital audio data in the Resource Interchange File Format (RIFF). It is a widely used format for storing and playing back audio data, particularly in the music and audio production industries. Wave files can be played back using a variety of audio players and editing software, and are commonly used for applications where high-quality, uncompressed audio is required.\n",
    "\n",
    "This notebook highlights the use of the wave and numpy Python modules to read wave file metadata, for understanding audio sampling. Audio sampling is the process of converting a continuous audio signal into a digital representation by capturing a series of discrete samples of the signal at regular intervals, with each sample representing the amplitude of the signal at a specific point in time, allowing the signal to be stored, transmitted, and reconstructed later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a Wave File\n",
    "\n",
    "The Python wave library is a module that provides an interface for reading and writing Wave audio files. The Python numpy library is a library for numerical computing, providing support for large, multi-dimensional arrays and matrices, and a wide range of high-performance mathematical functions.\n",
    "\n",
    "The following code imports the wave and numpy libraries, opens a WAV file, extracts its metadata (number of channels, sample width, frame rate, and number of frames), calculates the duration, and reads the audio data into a NumPy array using the frombuffer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "filename = \"./data/upland_chorus_frog_scp_20230222.wav\"\n",
    "\n",
    "with wave.open(filename, 'rb') as wav_file:\n",
    "    num_channels = wav_file.getnchannels()\n",
    "    sample_width = wav_file.getsampwidth()\n",
    "    frame_rate = wav_file.getframerate()\n",
    "    num_frames = wav_file.getnframes()\n",
    "    audio_data = np.frombuffer(wav_file.readframes(num_frames), dtype=np.int16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channels\n",
    "In a Wave file, a channel refers to a single audio stream or track, which can be either mono (single audio signal) or stereo (two audio signals, one for each ear), with each channel containing its own audio data, such as amplitude values, that are played back simultaneously to produce the overall audio signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_channels =  1\n",
      "Mono\n"
     ]
    }
   ],
   "source": [
    "print(\"num_channels = \", num_channels)\n",
    "\n",
    "if(num_channels == 1):\n",
    "    print(\"Mono\")\n",
    "elif(num_channels == 2):\n",
    "    print(\"Stereo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Width\n",
    "\n",
    "In a Wave file, the sample width refers to the number of bytes used to represent each audio sample, which can be 8 bits (1 byte) for 8-bit PCM, 16 bits (2 bytes) for 16-bit PCM, or 24 bits (3 bytes) for 24-bit PCM, determining the precision and range of the audio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample width :  2\n",
      "bits in byte:  8\n",
      "sample width in bits:  16\n"
     ]
    }
   ],
   "source": [
    "bits_in_byte = 8\n",
    "\n",
    "print(\"sample width : \", sample_width) # num bytes\n",
    "print(\"bits in byte: \", bits_in_byte)\n",
    "print(\"sample width in bits: \", sample_width * bits_in_byte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frames\n",
    "In a Wave file, a frame refers to a single block of audio data, consisting of a fixed number of samples, which are typically stored in a contiguous block of memory, with each frame representing a snapshot of the audio signal at a specific point in time, and being used to reconstruct the audio waveform during playback. Here, each frame is a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num frames: 323584\n"
     ]
    }
   ],
   "source": [
    "print(\"num frames:\", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Rate\n",
    "\n",
    "In a Wave file, the sampling rate, also known as the frame rate, refers to the number of times per second that the audio signal is sampled (captured), measured in Hertz (Hz), and determines the frequency resolution and playback quality of the audio. Hertz (Hz) is the unit of measurement for frequency, representing the number of cycles or oscillations per second of a wave or signal, with higher frequencies indicating more rapid oscillations and lower frequencies indicating slower oscillations.\n",
    "\n",
    "Common sampling rates for high-quality audio including 44.1 kHz, 48 kHz, and 96 kHz. Lower sampling rates are often used when quality is of less cocern, and smaller data sizes are preferred, such as 16 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling_rate:  44100  samples per second =  44100 Hz\n"
     ]
    }
   ],
   "source": [
    "print(\"sampling_rate: \", frame_rate, \" samples per second = \",  frame_rate, \"Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Duration\n",
    "\n",
    "To calculate the duration of a Wave file from the number of samples and the sample rate, you can use the following formula:\n",
    "\n",
    "Duration (seconds) = Number of Audio Samples / Sample Rate (Hz)\n",
    "\n",
    "Where:\n",
    "- Duration is the length of the audio file in seconds\n",
    "- Number of Samples is the total number of audio samples in the file\n",
    "- Sample Rate is the number of samples per second, measured in Hertz (Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 323584\n",
      "sample rate: 44100\n",
      "duration (seconds) =  323584 samples / 44100 Hz\n",
      "The audio file is approximately 7.3 seconds long\n"
     ]
    }
   ],
   "source": [
    "print(\"number of samples:\", num_frames) \n",
    "print(\"sample rate:\", frame_rate) \n",
    "\n",
    "\n",
    "print(\"duration (seconds) = \", num_frames, \"samples /\", frame_rate, \"Hz\")\n",
    "\n",
    "duration = num_frames / frame_rate\n",
    "\n",
    "print(\"The audio file is approximately {:.1f} seconds long\".format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
